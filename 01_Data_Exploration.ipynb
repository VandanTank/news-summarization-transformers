{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define the direct URLs to the script-free Parquet files\n",
    "data_files = {\n",
    "    \"train\": \"https://huggingface.co/datasets/EdinburghNLP/xsum/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\",\n",
    "    \"validation\": \"https://huggingface.co/datasets/EdinburghNLP/xsum/resolve/refs%2Fconvert%2Fparquet/default/validation/0000.parquet\",\n",
    "    \"test\": \"https://huggingface.co/datasets/EdinburghNLP/xsum/resolve/refs%2Fconvert%2Fparquet/default/test/0000.parquet\"\n",
    "}\n",
    "\n",
    "# Load the dataset by pointing directly to the Parquet files\n",
    "print(\"Loading XSum dataset from direct Parquet URLs...\")\n",
    "dataset = load_dataset(\"parquet\", data_files=data_files)\n",
    "\n",
    "# Print the dataset structure\n",
    "print(\"\\n--- Dataset Structure ---\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c59ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- First Training Example ---\")\n",
    "example = dataset['train'][0]\n",
    "\n",
    "print(\"\\n--- Document (Model Input) ---\")\n",
    "print(example['document'])\n",
    "\n",
    "print(\"\\n--- Summary (Model Target) ---\")\n",
    "print(example['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sample = dataset['train'].shuffle(seed=42).select(range(5000))\n",
    "validation_sample = dataset['validation'].shuffle(seed=42).select(range(1000))\n",
    "test_sample = dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# We can also put them back into a single DatasetDict for convenience\n",
    "from datasets import DatasetDict\n",
    "sampled_dataset = DatasetDict({\n",
    "    'train': train_sample,\n",
    "    'validation': validation_sample,\n",
    "    'test': test_sample\n",
    "})\n",
    "\n",
    "# Print the new, smaller dataset structure\n",
    "print(\"\\n--- Final Sampled DatasetDict ---\")\n",
    "print(sampled_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
