{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Reload all our models and tokenizers ---\n",
    "# We need these available in our new training notebook.\n",
    "# This will be fast as it uses the cache.\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_checkpoints = {\n",
    "    \"BART\": \"facebook/bart-base\",\n",
    "    \"T5\": \"t5-small\",\n",
    "    \"PEGASUS\": \"google/pegasus-xsum\"\n",
    "}\n",
    "\n",
    "tokenizers = {}\n",
    "models = {}\n",
    "\n",
    "print(\"--- Loading Models and Tokenizers ---\")\n",
    "for model_name, checkpoint in model_checkpoints.items():\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    tokenizers[model_name] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    models[model_name] = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "# --- Step 2: Load our pre-processed datasets from disk ---\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "tokenized_datasets = {}\n",
    "print(\"\\n--- Loading processed datasets from disk ---\")\n",
    "for model_name in model_checkpoints.keys():\n",
    "    data_dir = f\"./tokenized_data/{model_name}\"\n",
    "    print(f\"Loading {model_name} dataset from {data_dir}\")\n",
    "    tokenized_datasets[model_name] = load_from_disk(data_dir)\n",
    "\n",
    "print(\"\\n--- All models, tokenizers, and datasets are ready! ---\")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load the ROUGE metric from the 'evaluate' library\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "print(\"ROUGE metric loaded.\")\n",
    "\n",
    "# This is a critical function that will be called during training\n",
    "# It takes the model's predictions (eval_preds) and calculates the ROUGE score\n",
    "def compute_metrics(eval_preds):\n",
    "    # 'preds' are the raw logit outputs from the model\n",
    "    # 'labels' are the true token IDs for the summary\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # We need to convert the token IDs back into text\n",
    "    # We use batch_decode for this\n",
    "    # We skip special tokens (like <pad>) to get clean text\n",
    "    decoded_preds = tokenizers[\"BART\"].batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # We also need to decode the true labels\n",
    "    # We replace -100 (which are padding tokens) with the pad_token_id\n",
    "    # so they can be properly decoded\n",
    "    labels = np.where(labels != -100, labels, tokenizers[\"BART\"].pad_token_id)\n",
    "    decoded_labels = tokenizers[\"BART\"].batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Add a newline after each sentence for the ROUGE metric\n",
    "    decoded_preds = [\"\\n\".join(pred.strip().split()) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(label.strip().split()) for label in decoded_labels]\n",
    "\n",
    "    # Compute the ROUGE scores\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, \n",
    "        references=decoded_labels, \n",
    "        use_stemmer=True\n",
    "    )\n",
    "    \n",
    "    # Extract the main scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add a 'gen_len' (generated length) metric\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizers[\"BART\"].pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "print(\"compute_metrics() function is defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4edcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "# REMOVED: from transformers.training_args import IntervalStrategy \n",
    "\n",
    "# Check if CUDA is available (Expected to be False for the stable CPU path)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU (CUDA) is available! Training will be much faster.\")\n",
    "    use_fp16 = True \n",
    "else:\n",
    "    print(\"No GPU (CUDA) found. Proceeding with stable CPU training.\")\n",
    "    use_fp16 = False \n",
    "\n",
    "print(\"Training libraries imported and variables set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 in 03_Model_Training.ipynb - Launch Training\n",
    "\n",
    "# A dictionary to store our final results from the training run\n",
    "training_results = {}\n",
    "\n",
    "print(\"--- Starting Comparative Model Training Loop (CPU) ---\")\n",
    "\n",
    "# Loop through each model in our dictionary\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=========================================\")\n",
    "    print(f\"        Starting Training for {model_name}\")\n",
    "    print(f\"=========================================\")\n",
    "    \n",
    "    # Define the training configuration using stable string arguments\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"./{model_name}-finetuned\",\n",
    "        \n",
    "        # FINAL FIX: Using the shorter parameter name 'eval_strategy' for compatibility\n",
    "        eval_strategy=\"epoch\",  # Corrected parameter name\n",
    "        save_strategy=\"epoch\",                   \n",
    "        \n",
    "        # Core Hyperparameters\n",
    "        learning_rate=2e-5,                      \n",
    "        per_device_train_batch_size=4,           \n",
    "        per_device_eval_batch_size=4,            \n",
    "        num_train_epochs=3,                      # Train for 3 full passes\n",
    "        weight_decay=0.01,                       \n",
    "        save_total_limit=2,                      \n",
    "        \n",
    "        # CRITICAL for Summarization/Seq2Seq tasks\n",
    "        predict_with_generate=True,              \n",
    "        \n",
    "        # Windows/CPU Stability Settings:\n",
    "        fp16=False, # Explicitly disabling GPU mixed precision\n",
    "        dataloader_num_workers=0, # Ensures stable multiprocessing on Windows CPU\n",
    "        \n",
    "        # Evaluation Settings\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"rouge2\", # Use the ROUGE-2 score to determine the best checkpoint\n",
    "    )\n",
    "    \n",
    "    # The Data Collator prepares batches dynamically during training\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizers[model_name], \n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # The Trainer class manages the entire training and evaluation loop\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_datasets[model_name][\"train\"],\n",
    "        eval_dataset=tokenized_datasets[model_name][\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizers[model_name],\n",
    "        compute_metrics=compute_metrics  # Our ROUGE scoring function\n",
    "    )\n",
    "\n",
    "    # --- Start Training! ---\n",
    "    print(f\"Training {model_name}...\")\n",
    "    result = trainer.train()\n",
    "    \n",
    "    # Store the results of the training run\n",
    "    training_results[model_name] = result\n",
    "    \n",
    "    # --- Save the Final, Best Model (based on ROUGE-2) ---\n",
    "    print(f\"Saving best {model_name} model...\")\n",
    "    trainer.save_model(f\"./{model_name}-best-finetuned\")\n",
    "\n",
    "    print(f\"--- Finished with {model_name} ---\")\n",
    "\n",
    "print(\"\\n--- !!! ALL TRAINING COMPLETE !!! ---\")\n",
    "print(\"Final results:\", training_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
